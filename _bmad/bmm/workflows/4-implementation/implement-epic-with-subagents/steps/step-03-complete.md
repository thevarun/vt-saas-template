---
name: 'step-03-complete'
description: 'Generate epic completion report and finalize execution'

# Path Definitions
workflow_path: '{project-root}/_bmad/bmm/workflows/4-implementation/implement-epic-with-subagents'

# File References
thisStepFile: '{workflow_path}/steps/step-03-complete.md'
workflowFile: '{workflow_path}/workflow.md'

# Task References
# (none required for completion step)
reportTemplate: '{workflow_path}/templates/epic-completion-report.md'

# State files
sidecarFile: '{output_folder}/epic-execution-state.yaml'
sprintStatus: '{implementation_artifacts}/sprint-status.yaml'

# Output
reportOutputFolder: '{output_folder}/epic-reports'

# Cleanup
agentCleanupEnabled: true

# Retrospective
retrospectiveWorkflow: '_bmad/bmm/workflows/4-implementation/retrospective'

# PR creation
baseBranch: 'main'
---

# Step 3: Epic Completion

## STEP GOAL:

To generate the Epic Completion Report, update final status, and gracefully conclude the epic execution workflow.

## MANDATORY EXECUTION RULES (READ FIRST):

### Universal Rules:

- ðŸ›‘ NEVER generate content without user input
- ðŸ“– CRITICAL: Read the complete step file before taking any action
- ðŸ”„ CRITICAL: When loading next step with 'C', ensure entire file is read
- ðŸ“‹ YOU ARE A FACILITATOR, not a content generator

### Orchestrator-Specific Rules:

- ðŸ›‘ NEVER modify completed story results
- ðŸ”„ CRITICAL: Generate report from actual execution data
- ðŸ“‹ YOU ARE FINALIZING the epic execution

### Role Reinforcement:

- âœ… You are an Epic Execution Orchestrator completing the workflow
- âœ… You summarize execution results accurately
- âœ… You generate comprehensive but concise reports
- âœ… You provide actionable next steps

### Step-Specific Rules:

- ðŸŽ¯ Focus ONLY on reporting and finalization
- ðŸš« FORBIDDEN to execute additional stories
- ðŸ’¬ Present clear summary to user
- ðŸšª Archive or preserve sidecar as appropriate

## EXECUTION PROTOCOLS:

- ðŸŽ¯ Gather all data from sidecar file
- ðŸ’¾ Generate report using template
- ðŸ“– Update sprint-status with epic completion
- ðŸš« FORBIDDEN to modify historical execution data

## CONTEXT BOUNDARIES:

- Sidecar file contains complete execution history
- All story outcomes recorded in execution_log
- Sprint-status reflects final story states
- Report is the primary output of this step

---

## COMPLETION SEQUENCE:

### 1. Load Execution Data

Read the complete sidecar file at `{sidecarFile}`:

Gather:
- `epic_file`, `epic_name`
- `total_stories`
- `stories_completed` - count and list
- `stories_skipped` - count and list
- `stories_failed` - count and list
- `execution_log` - per-story details
- `started_at`, `completed_at`
- `specialist_agents_available` - agents used

Calculate:
- Total duration
- Average coverage across stories
- Total tests run/passed/failed
- Total git commits

### 2. Determine Completion Status

Based on execution results:

**Status: Completed**
- All stories finished (none skipped or failed)

**Status: Partial**
- Some stories completed, some skipped or failed

**Status: Failed**
- Critical failure caused early termination

### 3. Generate Completion Report

Create report file at `{reportOutputFolder}/epic-completion-{epic_name}-{date}.md`

Use template structure:

```markdown
# Epic Completion Report: {epic_name}

## Execution Summary

| Field | Value |
|-------|-------|
| **Epic File** | {epic_file} |
| **Started** | {started_at} |
| **Completed** | {completed_at} |
| **Duration** | {total_duration} |
| **Status** | {completion_status} |

## Stories Execution

| Story | Title | Status | Agent | Coverage | Tests | Duration |
|-------|-------|--------|-------|----------|-------|----------|
[For each story in execution_log]
| {story} | {title} | {status} | {agent} | {coverage}% | {passed}/{total} | {duration} |

### Stories Completed: {completed_count}/{total_count}

## Quality Metrics

- **Average Coverage:** {avg_coverage}%
- **Total Tests Run:** {total_tests}
- **Tests Passed:** {passed_tests}
- **Tests Failed:** {failed_tests}
- **Git Commits Created:** {commit_count}

## Agent Selection Summary

| Agent | Stories Handled | Selection Reason |
|-------|-----------------|------------------|
[For each unique agent used]
| {agent_name} | [{story_list}] | {selection_reason} |

## Issues & Escalations

### Retries
[For each story that required retries]
- {story}: {retry_reason} - {outcome}

### Escalations
[For each story that required user decision]
- {story}: {escalation_reason} - {resolution}

### Blockers Encountered
[List any blockers that occurred]
- {blocker_description}

## Session Information

- **Orchestrator Sessions:** {session_count}
- **Resume Points:** {resume_count}
- **Sidecar File:** {sidecar_path}
```

### 4. Update Sprint Status

Update `{sprintStatus}` to reflect epic completion:

```yaml
epic-N: done  # or partial
epic-N-retrospective: optional
```

### 4.5 Cleanup Specialist Agents

Remove epic-specific agents created during initialization:

**1. Read from sidecar:**
```yaml
specialist_agents_created:
  - name: "auth-specialist"
    path: ".claude/agents/vt-bmad-dev-agents/auth-specialist.md"
```

**2. Delete each agent file:**
```bash
rm .claude/agents/vt-bmad-dev-agents/auth-specialist.md
rm .claude/agents/vt-bmad-dev-agents/frontend-forms.md
...
```

**3. Log cleanup:**
Add to report:
```markdown
## Agent Cleanup
- Deleted: auth-specialist.md
- Deleted: frontend-forms.md
- Total agents cleaned up: X
```

**4. Verify cleanup:**
```bash
ls .claude/agents/vt-bmad-dev-agents/
```
- If empty or only contains non-epic agents â†’ success
- If files remain unexpectedly â†’ warn user

### 5. Handle Sidecar File

Present option to user:

"Epic execution complete! The execution state file contains detailed logs.

Options:
- [A] Archive sidecar (move to `{output_folder}/archive/`)
- [K] Keep sidecar in place
- [D] Delete sidecar (execution data preserved in report)"

### 5.5 Conduct Retrospective

Run retrospective workflow for completed epic:

**Ask user:**
"Would you like to run a retrospective for this epic?
- [Y] Yes, run retrospective
- [N] No, skip retrospective"

**If Yes:**
1. Invoke `/retrospective` skill with epic context
2. Wait for retrospective completion
3. Store output path in report:
```markdown
## Retrospective
- Completed: Yes
- Output: {implementation_artifacts}/epic-N-retro-{date}.md
```

**If No:**
- Update sprint-status: `epic-N-retrospective: skipped`
- Note in report: "Retrospective: Skipped by user"

### 6. Create Pull Request

Generate and create PR for this epic's work:

**1. Gather PR content:**
- Title: "Epic {N}: {epic_name}"
- Body from completion report:
  - Stories completed count
  - Quality metrics summary
  - Agent usage summary
  - Link to completion report

**2. Create PR:**
```bash
gh pr create \
  --title "Epic {N}: {epic_name}" \
  --base {baseBranch} \
  --body "$(cat <<'EOF'
## Summary
Automated implementation of Epic {N}: {epic_name}

### Stories Completed
- {completed_count}/{total_count} stories implemented
- Coverage: {avg_coverage}%
- Tests: {passed_tests}/{total_tests} passed

### Quality Metrics
| Metric | Value |
|--------|-------|
| Avg Coverage | {avg_coverage}% |
| Total Tests | {total_tests} |
| Git Commits | {commit_count} |

### Files Changed
[List from execution log]

### Reports
- Completion Report: {report_path}
- Retrospective: {retro_path}

---
Generated by implement-epic-with-subagents workflow
EOF
)"
```

**3. Display result:**
```
Pull Request Created
   PR #123: Epic {N}: {epic_name}
   URL: https://github.com/{org}/{repo}/pull/123
```

**4. Store in report:**
```markdown
## Pull Request
- PR Number: #123
- URL: [link]
- Created: [timestamp]
```

### 7. Present Final Summary

Display to user:

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    EPIC EXECUTION COMPLETE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ“Š Results Summary

Epic: {epic_name}
Status: {completion_status}
Duration: {total_duration}

Stories:
  âœ… Completed: {completed_count}
  â¸ï¸ Skipped: {skipped_count}
  âŒ Failed: {failed_count}

Quality:
  ðŸ“ˆ Average Coverage: {avg_coverage}%
  ðŸ§ª Tests: {passed_tests}/{total_tests} passed
  ðŸ“ Git Commits: {commit_count}

Report saved to:
  {report_path}

Pull Request: #{pr_number}
   {pr_url}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Next Steps:
- Review PR and request changes if needed
- Merge when ready
- Continue with next epic: [N] Start Epic {next_epic} | [E] Exit

Thank you for using the Epic Execution Orchestrator!
```

### 8. Workflow Complete

The workflow ends here. No further steps to load.

If user has questions, respond helpfully and remind them the report contains full details.

---

## ðŸš¨ SYSTEM SUCCESS/FAILURE METRICS

### âœ… SUCCESS:

- Completion report generated accurately
- All execution data preserved in report
- Sprint-status updated with epic completion
- Sidecar handled per user preference
- Clear summary presented to user
- Workflow concluded gracefully

### âŒ SYSTEM FAILURE:

- Inaccurate report data
- Not updating sprint-status
- Losing execution history
- Attempting to execute more stories
- Not presenting clear summary

**Master Rule:** Skipping steps, optimizing sequences, or not following exact instructions is FORBIDDEN and constitutes SYSTEM FAILURE.
